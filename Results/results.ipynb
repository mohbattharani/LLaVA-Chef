{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3060a016-9f59-4c8c-a27f-061e77582700",
   "metadata": {},
   "source": [
    "Models for testing:\n",
    "\n",
    "- llama: Testing is in process on AIMOS\n",
    "- llama-2: Could not download weights\n",
    "- llava: Tested completed for 50K samples on AIMOS\n",
    "- chef-transformer (t5): Testing completed. \n",
    "- mistral: testing on andes (ETA: 44 hrs)\n",
    "- llava-chef (our fine-tuned version)\n",
    "\n",
    "##### First, I tried to test on all samples that takes long time. Therefore, I have randomly selected 5000 samples from test set. First, I want to test all models on these 5000 samples and then may test the best model on whole test set from Recipe1M dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc56085a-bd86-47c7-b2fd-457bb16d7b82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-09 18:57:44,837] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import os, json, sys, torch\n",
    "from metrics import compute_metrics, compute_metrics_hf\n",
    "from metrics import save_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f4418-658a-4ecb-8005-64892b3168b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aadae4e3-6236-4c09-9c44-41f78a4ef01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cheft5_recipe.json : 50507\n",
      "llava_recipe.json : 50507\n",
      "llava_chef_recipe.json : 50507\n",
      "mistral_recipe.json : 19226\n",
      "llama_recipe.json : 57033\n",
      "==================================================\n",
      "llavachef_recipe.json : 1000\n",
      "llava_recipe_onlyimage.json : 991\n",
      "llava_recipe.json : 1000\n",
      "cheft5_recipe1k.json : 1000\n",
      "llavachef_recipe_ImageTitle.json : 1000\n",
      "llavachef_recipe_ImageIng.json : 989\n",
      "llava_recipe_ImageIng.json : 989\n",
      "llava_recipe_noimage.json : 1000\n",
      "llavachef_recipe_onlytitle.json : 1000\n",
      "llavachef_recipe_onlyimage.json : 998\n",
      "llavachef_recipe_noimage.json : 1000\n",
      "llama_recipe1k.json : 1000\n",
      "mistral_recipe1k.json : 1000\n",
      "llava_recipe_ImageTitle.json : 992\n",
      "llava_recipe_onlyTitle.json : 1000\n",
      "==================================================\n",
      "mistral_recipe5k.json : 5000\n",
      "llava_recipe5k.json : 5000\n",
      "mistral5k.json : 5000\n",
      "llavachef_recipe5k.json : 5000\n",
      "llama_recipe5k.json : 5000\n",
      "cheft5_recipe5k.json : 5000\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "save_dir = \"results/\"\n",
    "files = os.listdir (save_dir)\n",
    "for fi in files:\n",
    "    if (fi.endswith (\".json\")):\n",
    "        file = save_dir + f\"{fi}\"\n",
    "        data = json.load (open(file))\n",
    "        print (f\"{fi} : {len(data)}\")\n",
    "\n",
    "print (\"=\" * 50)\n",
    "save_dir = \"results1k/\"\n",
    "files = os.listdir (save_dir)\n",
    "\n",
    "for fi in files:\n",
    "    if (fi.endswith (\".json\")):\n",
    "        file = save_dir + f\"{fi}\"\n",
    "        data = json.load (open(file))\n",
    "        print (f\"{fi} : {len(data)}\")\n",
    "print (\"=\" * 50)\n",
    "\n",
    "\n",
    "save_dir = \"results5k/\"\n",
    "files = os.listdir (save_dir)\n",
    "for fi in files:\n",
    "    if (fi.endswith (\".json\")):\n",
    "        file = save_dir + f\"{fi}\"\n",
    "        data = json.load (open(file))\n",
    "        print (f\"{fi} : {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b4a15dc-19d0-4715-9fb4-1e9f804193b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 991 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112857 tokens at 819879.36 tokens per second.\n",
      "PTBTokenizer tokenized 214488 tokens at 1310429.17 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 170465, 'reflen': 96377, 'guess': [170465, 169478, 168491, 167504], 'correct': [25834, 3713, 707, 151]}\n",
      "ratio: 1.768731128796271\n",
      "computing metrics on 991 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8f6ab5e1df44918141d55fbcf32c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c823970ccafd4e61881d2e4caef2d616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 989 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112500 tokens at 979100.41 tokens per second.\n",
      "PTBTokenizer tokenized 200425 tokens at 1508861.36 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 167264, 'reflen': 96066, 'guess': [167264, 166275, 165286, 164297], 'correct': [46338, 12491, 3855, 1338]}\n",
      "ratio: 1.7411363021256037\n",
      "computing metrics on 989 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a35be8d3784d15af989aa9b5e59147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d6bb66e5304a2e9195b82ed1216ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 113888 tokens at 1040817.11 tokens per second.\n",
      "PTBTokenizer tokenized 202655 tokens at 1502379.42 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 169000, 'reflen': 97261, 'guess': [169000, 168001, 167002, 166003], 'correct': [49542, 14135, 4612, 1711]}\n",
      "ratio: 1.7375926630406664\n",
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0c7b4c7b0941dfb53f1ef41dbbe98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd4ef3802fd4e7aaefaa0dd5acc4801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 992 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112887 tokens at 930517.32 tokens per second.\n",
      "PTBTokenizer tokenized 225185 tokens at 1619381.79 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 180485, 'reflen': 96393, 'guess': [180485, 179497, 178509, 177521], 'correct': [28552, 4166, 785, 170]}\n",
      "ratio: 1.8723869990559285\n",
      "computing metrics on 992 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd2185e78f044a948b0b5972142e9163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c733c0c1888745739e32b64a33871f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 113888 tokens at 1005943.35 tokens per second.\n",
      "PTBTokenizer tokenized 217471 tokens at 1413119.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 172305, 'reflen': 97261, 'guess': [172305, 171307, 170309, 169311], 'correct': [36779, 8177, 2215, 667]}\n",
      "ratio: 1.7715733952971717\n",
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad83ebab03294bada38b504c6bef5578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca45bc83717448e8b0c89e09fed4edfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 113889 tokens at 941191.12 tokens per second.\n",
      "PTBTokenizer tokenized 204904 tokens at 1477902.95 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 171097, 'reflen': 97261, 'guess': [171097, 170097, 169097, 168097], 'correct': [49639, 13981, 4615, 1695]}\n",
      "ratio: 1.7591532063211177\n",
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25194104a72434a8a7f04cdbd1fb2d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78fa953428440e1838033a59ee3e532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = \"results1k/\"\n",
    "results = []\n",
    "\n",
    "files = os.listdir (dir)\n",
    "for fi in files:\n",
    "    file = dir + f\"{fi}\"\n",
    "    if (file.endswith (\".json\") and \"llava_\" in fi):\n",
    "        result = compute_metrics (file)\n",
    "        result_hf = compute_metrics_hf (file)\n",
    "        result.update (result_hf)\n",
    "        result[\"method\"] = fi\n",
    "        results.append (result)\n",
    "save_results (results, \"results1k_llava_newlines_removed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d838c428-1f7d-49e9-98bf-eaf5afeb68c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 998 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 113730 tokens at 816619.83 tokens per second.\n",
      "PTBTokenizer tokenized 83472 tokens at 662158.43 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 68606, 'reflen': 97126, 'guess': [68606, 67608, 66610, 65612], 'correct': [33970, 11507, 4565, 1968]}\n",
      "ratio: 0.706360809669906\n",
      "computing metrics on 998 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03192f4ca66c42ccb7e49021f1732b3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47174ee2be444d86b4f1666399693c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 113886 tokens at 818540.67 tokens per second.\n",
      "PTBTokenizer tokenized 81566 tokens at 670182.02 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 67127, 'reflen': 97261, 'guess': [67127, 66127, 65127, 64128], 'correct': [33617, 11478, 4511, 1929]}\n",
      "ratio: 0.6901738620824308\n",
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca3d77e8b7a4f6ba5132cad0f4fc179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b160c06ec84f45f79de2ae387ce7ac9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 113886 tokens at 800442.89 tokens per second.\n",
      "PTBTokenizer tokenized 83747 tokens at 697012.64 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 67593, 'reflen': 97261, 'guess': [67593, 66593, 65595, 64600], 'correct': [23752, 6062, 1942, 696]}\n",
      "ratio: 0.6949650939225311\n",
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af4a02e09e14170b9391446b5457a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5341b2cb1d8941169c4a7c35472b1a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 989 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 112626 tokens at 794176.52 tokens per second.\n",
      "PTBTokenizer tokenized 71330 tokens at 603756.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 57750, 'reflen': 96175, 'guess': [57750, 56761, 55772, 54783], 'correct': [28379, 9010, 3491, 1475]}\n",
      "ratio: 0.6004678970626399\n",
      "computing metrics on 989 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e767ef396e0348a897a6a51d6e829feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec035420f3db4ae79972330e9bdcbfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 113886 tokens at 996095.42 tokens per second.\n",
      "PTBTokenizer tokenized 85506 tokens at 829472.68 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 68767, 'reflen': 97261, 'guess': [68767, 67767, 66767, 65769], 'correct': [23366, 5651, 1795, 651]}\n",
      "ratio: 0.7070357080432988\n",
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566b15e471fb4338a46bc6ec7e701830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c477ca650c3642c1aa43d4dd7e370902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 998 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 113693 tokens at 968782.76 tokens per second.\n",
      "PTBTokenizer tokenized 69614 tokens at 682529.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 58058, 'reflen': 97095, 'guess': [58058, 57060, 56062, 55064], 'correct': [16385, 2731, 631, 180]}\n",
      "ratio: 0.5979504608888141\n",
      "computing metrics on 998 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "080554feea62469888144475ba684cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69706bb1d75444f8434812732d2ae78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 113886 tokens at 968172.73 tokens per second.\n",
      "PTBTokenizer tokenized 82701 tokens at 827693.60 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 68065, 'reflen': 97261, 'guess': [68065, 67065, 66065, 65065], 'correct': [33945, 11622, 4612, 2016]}\n",
      "ratio: 0.6998180154429761\n",
      "computing metrics on 1000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc459bef41e54ddf93a8b175b034fc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909ac58849b54711aee384bd56ca75ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dir = \"results1k/\"\n",
    "results = []\n",
    "\n",
    "files = os.listdir (dir)\n",
    "for fi in files:\n",
    "    file = dir + f\"{fi}\"\n",
    "    if (file.endswith (\".json\")):\n",
    "        if (file.endswith (\".json\") and \"llavachef_\" in fi):\n",
    "            result = compute_metrics (file)\n",
    "            result_hf = compute_metrics_hf (file)\n",
    "            result.update (result_hf)\n",
    "            result[\"method\"] = fi\n",
    "            results.append (result)\n",
    "save_results (results, \"results1k_llavachefv1_newlines_removed.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7692b03d-fb49-4183-aeea-bdb24f9b1244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b95f66-5214-4041-a63b-b54f9203c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 5000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 582002 tokens at 2536933.79 tokens per second.\n",
      "PTBTokenizer tokenized 317794 tokens at 1871512.19 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 252952, 'reflen': 498117, 'guess': [252952, 248003, 243123, 238332], 'correct': [86818, 28945, 12832, 6603]}\n",
      "ratio: 0.5078164367006135\n",
      "computing metrics on 5000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 582002 tokens at 2504351.45 tokens per second.\n",
      "PTBTokenizer tokenized 1029133 tokens at 3247035.03 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 858715, 'reflen': 498117, 'guess': [858715, 853718, 848721, 843724], 'correct': [253001, 72413, 23977, 8896]}\n",
      "ratio: 1.7239222913492178\n",
      "computing metrics on 5000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 687277 tokens at 2610274.89 tokens per second.\n",
      "PTBTokenizer tokenized 344402 tokens at 1919632.04 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 274305, 'reflen': 591042, 'guess': [274305, 269356, 264472, 259693], 'correct': [102844, 35926, 16017, 8207]}\n",
      "ratio: 0.4641040738221641\n",
      "computing metrics on 5000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 582002 tokens at 2462054.22 tokens per second.\n",
      "PTBTokenizer tokenized 420391 tokens at 2097220.20 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 346239, 'reflen': 498117, 'guess': [346239, 341239, 336239, 331240], 'correct': [173083, 59224, 23391, 10128]}\n",
      "ratio: 0.6950957305211413\n",
      "computing metrics on 3131 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 363777 tokens at 1957126.05 tokens per second.\n",
      "Jan 09, 2024 4:39:27 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 577489 tokens at 2243203.58 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 502359, 'reflen': 311288, 'guess': [502359, 499228, 496097, 492966], 'correct': [119970, 31335, 10451, 4238]}\n",
      "ratio: 1.6138077921410348\n",
      "computing metrics on 5000 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 582002 tokens at 2468683.59 tokens per second.\n",
      "PTBTokenizer tokenized 504901 tokens at 2415414.88 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 430003, 'reflen': 498117, 'guess': [430003, 425910, 421819, 417732], 'correct': [132783, 29568, 7752, 2450]}\n",
      "ratio: 0.8632570259597627\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "save_dir = \"results5k/\"\n",
    "files = os.listdir (save_dir)\n",
    "\n",
    "N = -1\n",
    "for fi in files:\n",
    "    file = save_dir + f\"{fi}\"\n",
    "    if (file.endswith (\".json\")):\n",
    "        result = compute_metrics (file, N = N)\n",
    "        #result_hf = compute_metrics_hf (file, N = N)\n",
    "        #result.update (result_hf)\n",
    "        result[\"method\"] = fi\n",
    "        results.append (result)\n",
    "\n",
    " \n",
    "save_results (results, \"results5k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb7b751-7ce1-4dcc-8ccd-352d62f8b408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing metrics on 50507 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 5921999 tokens at 5267201.33 tokens per second.\n",
      "PTBTokenizer tokenized 5170222 tokens at 5189815.73 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 4403042, 'reflen': 5069216, 'guess': [4403042, 4361435, 4319842, 4278272], 'correct': [1369820, 307587, 81213, 25418]}\n",
      "ratio: 0.8685844122641448\n",
      "computing metrics on 50507 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 5921999 tokens at 4963424.23 tokens per second.\n",
      "PTBTokenizer tokenized 10405507 tokens at 4844708.27 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 8682575, 'reflen': 5069216, 'guess': [8682575, 8632100, 8581625, 8531150], 'correct': [2575843, 735958, 241278, 89718]}\n",
      "ratio: 1.7128043074116388\n",
      "computing metrics on 50507 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 5921999 tokens at 4952860.59 tokens per second.\n",
      "PTBTokenizer tokenized 4266805 tokens at 4972772.92 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 3513870, 'reflen': 5069216, 'guess': [3513870, 3463364, 3412859, 3362356], 'correct': [1762335, 603301, 238341, 103737]}\n",
      "ratio: 0.6931781956026335\n",
      "computing metrics on 19226 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 2237414 tokens at 4230409.52 tokens per second.\n",
      "PTBTokenizer tokenized 1217636 tokens at 3335738.28 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 969326, 'reflen': 1915022, 'guess': [969326, 950292, 931507, 913085], 'correct': [331381, 110281, 48563, 24768]}\n",
      "ratio: 0.5061696419153406\n",
      "computing metrics on 57033 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 7517246 tokens at 5189261.79 tokens per second.\n",
      "Jan 09, 2024 5:17:34 PM edu.stanford.nlp.process.PTBLexer next\n",
      "WARNING: Untokenizable: � (U+FFFD, decimal: 65533)\n",
      "PTBTokenizer tokenized 10770630 tokens at 4896418.09 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'testlen': 9365581, 'reflen': 6453527, 'guess': [9365581, 9308548, 9251515, 9194482], 'correct': [2355186, 619925, 203264, 82121]}\n",
      "ratio: 1.4512344954937042\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "save_dir = \"results/\"\n",
    "files = os.listdir (save_dir)\n",
    "\n",
    "N = -1\n",
    "for fi in files:\n",
    "    file = save_dir + f\"{fi}\"\n",
    "    if (file.endswith (\".json\")):\n",
    "        result = compute_metrics (file, N = N)\n",
    "        #result_hf = compute_metrics_hf (file, N = N)\n",
    "        #result.update (result_hf)\n",
    "        result[\"method\"] = fi\n",
    "        results.append (result)\n",
    "\n",
    " \n",
    "save_results (results, \"results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4336e6ae-668b-4218-ba51-6fb4adea4302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ba4621-c9d1-4c64-a01a-861421a5b2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82c894-3605-4f21-8e5f-3cfba201058e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7284b09d-3784-4a5e-8250-c7f8c4b1a451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ea2afe-79b1-4fe2-a72b-634cd69f1799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "680a57db-c753-49e4-8126-07ba4fd545bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12345679011\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818a9cf-60dd-445e-984c-c811455d7180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
